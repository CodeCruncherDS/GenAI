ChatKit App Deployment Blueprint
Lab type

Deployment blueprint

Duration

~30 minutes

Level

Intermediate

Environment

ChatKit + backend

Stack

Node/Express + React

Focus

Secure app embed

Jump to

Step 1
Step 2
Step 3
Step 4
Step 5
Step 6
Extra
References
This section shows how to take a workflow you built in Agent Builder and embed it in your own app with ChatKit. You will capture the workflow ID, mint secure sessions from your backend, and render the ChatKit panel inside a React front end.
Step 1 — Finalize your workflow
In the Agent Builder (Agent/Workflow UI), create or publish the workflow you want to expose.
Copy the resulting workflow_id—you will pass this to ChatKit when minting sessions.
Keep your workflow under source control (versioned JSON) so you know which revision is in production.
Starter repos

Clone openai-chatkit-starter-app (FastAPI + React) or openai-chatkit-advanced-samples (FastAPI + Vite/React) from GitHub if you prefer a ready-made scaffold.
Step 2 — Backend session endpoint (Node + Express)
The backend exchanges your OpenAI API key for a ChatKit session token. The client never sees the API key.
Install
npm init -y
npm i express node-fetch dotenv
Environment
# .env
OPENAI_API_KEY=sk-...
PORT=4000
WORKFLOW_ID=your_workflow_id_here
server.js
import express from "express";
import fetch from "node-fetch";
import dotenv from "dotenv";
dotenv.config();

const app = express();
app.use(express.json());

app.post("/api/session", async (req, res) => {
  try {
    const resp = await fetch("https://api.openai.com/v1/chatkit/sessions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        workflow: process.env.WORKFLOW_ID,
        user: { id: req.body.userId || "anon", name: req.body.name || "Guest" },
        // optional: display_name, external_documents, initial_variables, metadata
      }),
    });

    if (!resp.ok) {
      const errText = await resp.text();
      return res.status(resp.status).send(errText);
    }

    const body = await resp.json();
    res.json(body); // return client_secret / session payload to the browser
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: err.message });
  }
});

app.listen(process.env.PORT || 4000, () => {
  console.log("Server listening", process.env.PORT || 4000);
});
Keep secrets server-side

The /v1/chatkit/sessions call belongs on the server only. Never expose OPENAI_API_KEY or WORKFLOW_ID to the client—always return a short-lived session/client secret instead.
Step 3 — Frontend embed with chatkit-js
Use Vite/React (or Next.js) with the ChatKit client SDK.
npm create vite@latest my-chatkit-app -- --template react
cd my-chatkit-app
npm install @openai/chatkit-js
ChatPanel.jsx
import { useEffect, useRef } from "react";
import { ChatKitClient } from "@openai/chatkit-js";

export default function ChatPanel({ backendUrl = "/api" }) {
  const containerRef = useRef(null);

  useEffect(() => {
    async function init() {
      const resp = await fetch(`${backendUrl}/session`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ userId: "user-123", name: "Shikhar" }),
      });
      const session = await resp.json();

      const client = new ChatKitClient({ session });
      client.createPanel({
        target: containerRef.current,
        config: { title: "Support Assistant", showExamples: true },
      });

      client.on("action", (action) => console.log("action triggered", action));
    }

    init();
  }, [backendUrl]);

  return <div ref={containerRef} style={{ height: "700px", width: "100%" }} />;
}
import ChatPanel from "./ChatPanel";

export default function App() {
  return (
    <div className="App">
      <ChatPanel backendUrl="http://localhost:4000/api" />
    </div>
  );
}
Step 4 — Streaming, actions, external docs
Streaming: ChatKit streams tokens via SSE/WebSockets automatically when you use the SDK. If you proxy responses manually, remember to forward the SSE stream.
Actions: Define actions in your workflow (open drawers, trigger tool calls) and handle them via client.on("action") for custom behavior.
External docs: Attach URLs, PDFs, or CSVs as external_documents so the agent can cite them in context.
Step 5 — Theming & custom UI
The default panel can be themed (colors, typography, message bubbles).
For complete control, render your own UI and call the underlying ChatKit client methods (client.messages.send, streaming hooks, widget events).
Inspect @openai/chatkit-js examples for Web Components or iframe-based embeds if React is not an option.
Step 6 — Security, CORS, and deploy checklist
Keep OPENAI_API_KEY in the backend; mint short-lived sessions only.
Allowlist your production domains inside the OpenAI dashboard before launch.
Add CORS + rate limiting to /api/session; require auth (cookies, JWT, or OAuth) so anonymous users cannot mint unlimited sessions.
Ensure your hosting provider supports SSE/WebSockets if you depend on streaming.
Monitor usage and enforce guardrails/quotas within your workflow (fallback flows, eval alerts).
Extra — Deploy & operations
Deploy frontend on Vercel/Netlify and backend on Vercel functions, Fly.io, Heroku, AWS, or GCP—just ensure the backend supports the streaming duration you need.
Add logging/observability for /api/session calls and ChatKit actions.
Create an evals pipeline to measure answer quality and auto-trigger re-prompts or human review.
Reference links
ChatKit guide (https://platform.openai.com/docs/guides/chatkit)
ChatKit API reference (https://platform.openai.com/docs/api-reference/chatkit)
chatkit-js SDK (https://github.com/openai/chatkit-js)
Starter apps (FastAPI + React) (https://github.com/openai/openai-chatkit-starter-app)
Advanced samples (https://github.com/openai/openai-chatkit-advanced-samples)
Widgets & embedding reference (https://platform.openai.com/docs/guides/chatkit/widgets)